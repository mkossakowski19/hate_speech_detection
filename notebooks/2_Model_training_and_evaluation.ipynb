{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the process of training a classification model for a hate-speech dataset. The possible targets for each entity are:\n",
    "- 0: non-harmful\n",
    "- 1: cyberbullying (addressed towards a single person)\n",
    "- 2: hate-speech (addressed towards a public person/entity/large group)\n",
    "\n",
    "The dataset comes from the 2019 PolEval competition: http://2019.poleval.pl/index.php/tasks/task6\n",
    "\n",
    "The original training set will be split into two subsets: 75% for training the models, 25% for validation. The class responsible for that is defined in the codebase.\n",
    "\n",
    "After the splitting operation, I will perform data augmentation on the training subset for the undersampled classes 1 and 2.\n",
    "The augmentation logic will be using the Google Translate API to translate some sentences from Polish to English, and then back to Polish.\n",
    "This way, we should get the sentences having the same context, but put in a different words.\n",
    "However if this causes data duplication, I will not proceed with this technique.\n",
    "\n",
    "Every observation will be cleaned using the TextPreprocessor class defined in the codebase. The steps are:\n",
    "- putting all text to lowercase,\n",
    "- removing emojis,\n",
    "- removing user mentions (ex. @mariusz)\n",
    "- removing stop words,\n",
    "- removing URL addresses,\n",
    "- removing special characters like new line, carriage return, tab,\n",
    "- removing hashtags,\n",
    "- removing punctuation marks,\n",
    "- removing redundant spaces.\n",
    "\n",
    "I decided to use the SVM algorithm, which should be a good balance between simplicity and performance. Also, it was SVM which took the first place in the PolEval compoetition :)\n",
    "\n",
    "The text data will have to be transformed into numbers. I will use the TF-IDF vectorizer for that purpose.\n",
    "\n",
    "In the first approach, both SVM and TFIDF will be trained on default hyperparameters (I will just pass the max_features parameter to TFIDF so that we don't get more features than observations in the training dataset).\n",
    "\n",
    "In the second approach, I will perform hyperparameter tuning with Optuna, using the hyperparameters ranges specified in the \"hyperparameters.yaml\" file. I will choose the best configuration at the end.\n",
    "\n",
    "The results of both approaches will be evaluated by the TextClassificationEvaluator class defined in the codebase.\n",
    "\n",
    "Default approach, hyperparameters tuning and best hyperparams will be logged in MLflow.\n",
    "\n",
    "The approaches will be tested on the original \"test\" dataset.\n",
    "\n",
    "Considering the facts that the model is expected to be a prototype and we're dealing with the multiclass classification problem, I do not have any strict expectations regarding to the metrics. The main goal is to show a process of data preparation and modelling, and later propose a deployment strategy.\n",
    "\n",
    "The approach with best results will be chosen to be deployed as a working service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I install the googletrans package here to avoid coflicts with pytest http\n",
    "!pip install googletrans==3.1.0a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from googletrans import Translator\n",
    "\n",
    "from src.text_preprocessor import TextPreprocessor\n",
    "from model_training.text_classification_evaluator import TextClassificationEvaluator\n",
    "from model_training.config_parser import ConfigParser\n",
    "from model_training.train_test_split_transformation import TrainValidationSplitTransformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(text_path: str, labels_path: str):\n",
    "    with open(text_path, \"r\") as f:\n",
    "        examples = f.readlines()\n",
    "\n",
    "    with open(labels_path, \"r\") as f:\n",
    "        labels = f.readlines()\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"text\": train_examples,\n",
    "        \"label\": train_labels,\n",
    "    })\n",
    "\n",
    "    df[\"label\"] = df[\"label\"].apply(lambda x: x.replace(\"\\n\", \"\"))\n",
    "    df[\"label\"] = df[\"label\"].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = load_data(\"data/train/training_set_clean_only_text.txt\", \"data/train/training_set_clean_only_tags.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dla mnie faworytem do tytu≈Çu bƒôdzie Cracovia. Zobaczymy, czy typ siƒô sprawdzi.\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@anonymized_account @anonymized_account Brawo ty Daria kibic ma byƒá na dobre i z≈Çe\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@anonymized_account @anonymized_account Super, polski premier sk≈Çada kwiaty na grobach kolaborant√≥w. Ale doczekali≈õmy czas√≥w.\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@anonymized_account @anonymized_account Musi. Innej drogi nie mamy.\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Odrzut natychmiastowy, kwa≈õna mina, mam problem\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jaki on by≈Ç fajny xdd pamiƒôtam, ≈ºe sp√≥≈∫ni≈Çam siƒô na jego pierwsze zajƒôcia i to sporo i za karƒô kaza≈Ç mi usiƒÖ≈õƒá w pierwszej ≈Çawce XD\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@anonymized_account No nie ma u nas szczƒô≈õcia üòâ\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@anonymized_account Dawno kogo≈õ tak wrednego nie widzia≈Çam xd\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@anonymized_account @anonymized_account Zaleg≈Ço≈õci by≈Çy, ale wa≈ºne czy by≈Çy wezwania do zap≈Çaty z kt√≥rych siƒô klub nie wywiƒÖza≈Ç.\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@anonymized_account @anonymized_account @anonymized_account Gdzie jest @anonymized_account . Brudzi≈Ñski jeste≈õ k≈ÇamcƒÖ i marnym kutasem @anonymized_account\\n</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                           text  \\\n",
       "0                                                                              Dla mnie faworytem do tytu≈Çu bƒôdzie Cracovia. Zobaczymy, czy typ siƒô sprawdzi.\\n   \n",
       "1                                                                          @anonymized_account @anonymized_account Brawo ty Daria kibic ma byƒá na dobre i z≈Çe\\n   \n",
       "2                               @anonymized_account @anonymized_account Super, polski premier sk≈Çada kwiaty na grobach kolaborant√≥w. Ale doczekali≈õmy czas√≥w.\\n   \n",
       "3                                                                                         @anonymized_account @anonymized_account Musi. Innej drogi nie mamy.\\n   \n",
       "4                                                                                                             Odrzut natychmiastowy, kwa≈õna mina, mam problem\\n   \n",
       "5                         Jaki on by≈Ç fajny xdd pamiƒôtam, ≈ºe sp√≥≈∫ni≈Çam siƒô na jego pierwsze zajƒôcia i to sporo i za karƒô kaza≈Ç mi usiƒÖ≈õƒá w pierwszej ≈Çawce XD\\n   \n",
       "6                                                                                                             @anonymized_account No nie ma u nas szczƒô≈õcia üòâ\\n   \n",
       "7                                                                                               @anonymized_account Dawno kogo≈õ tak wrednego nie widzia≈Çam xd\\n   \n",
       "8                            @anonymized_account @anonymized_account Zaleg≈Ço≈õci by≈Çy, ale wa≈ºne czy by≈Çy wezwania do zap≈Çaty z kt√≥rych siƒô klub nie wywiƒÖza≈Ç.\\n   \n",
       "9  @anonymized_account @anonymized_account @anonymized_account Gdzie jest @anonymized_account . Brudzi≈Ñski jeste≈õ k≈ÇamcƒÖ i marnym kutasem @anonymized_account\\n   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "5      0  \n",
       "6      0  \n",
       "7      0  \n",
       "8      0  \n",
       "9      2  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10041 entries, 0 to 10040\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    10041 non-null  object\n",
      " 1   label   10041 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 157.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10041, 2)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into training and validation subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_valid_transformation = TrainValidationSplitTransformation(\n",
    "    input_column_name=\"text\",\n",
    "    target_column_name=\"label\",\n",
    "    train_size=0.75,\n",
    "    do_stratify=True,\n",
    ")\n",
    "\n",
    "df_train, df_val = train_valid_transformation.split_to_training_and_val_subsets(dataframe=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7530, 2)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2511, 2)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.915272\n",
       "2    0.059495\n",
       "1    0.025232\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.915173\n",
       "2    0.059737\n",
       "1    0.025090\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting classes 1 and 2 - experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rephrase_text(\n",
    "    text: str,\n",
    "    translator_object: Translator = translator\n",
    ") -> str:\n",
    "    english_text = translator_object.translate(text, src=\"pl\", dest=\"en\")\n",
    "    rephrased_text = translator_object.translate(english_text, src=\"en\", dest=\"pl\").text\n",
    "    start_index = rephrased_text.index(\"text\") + 5\n",
    "    end_index = rephrased_text.index(\"wymowa\") - 2\n",
    "    return rephrased_text[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_indices = range(12)\n",
    "sample_sentences = df_train[\"text\"].values[sample_indices]\n",
    "rephrased_sentences = [rephrase_text(text) for text in sample_sentences]\n",
    "rephrasing_sample = pd.DataFrame({\n",
    "    \"original\": sample_sentences,\n",
    "    \"rephrased\": rephrased_sentences,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>rephrased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Justas Lasickas z golem dla Litwy U-21, kt√≥ra remisuje z Wyspami Owczymi 2:2.\\n</td>\n",
       "      <td>Justas Lasickas po golu dla Litwy U-21, kt√≥ry zremisowa≈Ç z Wyspami Owczymi 2-2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@anonymized_account @anonymized_account Kostevycha rƒôka by≈Ça rozmy≈õlna ?\\n</td>\n",
       "      <td>@anonymized_account @anonymized_account Rƒôka Kostevycha by≈Ça celowa?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@anonymized_account Ja ju≈º nie odczuwam, regularno≈õƒá codziennie do pracy, ≈õmiejƒô siƒô wiatru w twarz, czym mocniej wieje tym g≈Ço≈õniej si√© ≈õmiejƒô\\n</td>\n",
       "      <td>@anonymized_account Ju≈º tego nie czujƒô, regularno≈õƒá codziennie do pracy, ≈õmiejƒô siƒô w twarz wiatrowi, im mocniej wieje, tym g≈Ço≈õniej siƒô ≈õmiejƒô</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@anonymized_account @anonymized_account Nikt ciebie tu nie chce rasistowski pƒôtaku\\n</td>\n",
       "      <td>@anonymized_account @anonymized_account Nikt ciƒô tu nie chce rasistowski draniu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#dividetourwarsaw zr√≥b ktos live spod stadionu prosze potrzebuje tego\\n</td>\n",
       "      <td>#dividetourwarsaw czy kto≈õ na ≈ºywo spod stadionu proszƒô potrzebujƒô tego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@anonymized_account @anonymized_account @anonymized_account @anonymized_account @anonymized_account Kaliciaka mogli te≈º zaprosiƒá :)\\n</td>\n",
       "      <td>@anonymized_account @anonymized_account @anonymized_account @anonymized_account @anonymized_account Kaliciak te≈º m√≥g≈Ç zaprosiƒá :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@anonymized_account Mo≈ºe nie by≈Ço ciekawszych? :) a mo≈ºe ta agencja ma te≈º znajomo≈õci w gazecie i poprosili ≈ºeby o nim wspomnieƒá ? :)\\n</td>\n",
       "      <td>@anonymized_account Mo≈ºe nie by≈Ço ciekawiej? :) a mo≈ºe ta agencja te≈º ma znajomo≈õci w gazecie i poprosili mnie o wzmiankƒô o nim? :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@anonymized_account @anonymized_account @anonymized_account Masz racjƒô w ka≈ºdym punkcie. I PiS te≈º ma i dok≈Çadnie wie co robi i z kim ma do czynienia.\\n</td>\n",
       "      <td>@anonymized_account @anonymized_account @anonymized_account Masz racjƒô w ka≈ºdym punkcie. A PiS te≈º ma i dok≈Çadnie wie, co robi iz kim ma do czynienia.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>W sumie to polubi≈Çam ju≈º zajƒôcia z konstrukcji przekazu reklamowego i prowadzƒÖcy jest ≈õwietny\\n</td>\n",
       "      <td>W sumie ju≈º mi siƒô podoba≈Çy zajƒôcia z budowy przekazu reklamowego i prowadzƒÖcy jest super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T≈Çit aktualny szczeg√≥lnie dzisiaj‚ÄºÔ∏è\\n\\nDziƒôki @anonymized_account \\n\\nhttps://t.co/w4nJSmo1J4\\n</td>\n",
       "      <td>Ttit aktualne szczeg√≥lnie dzisiaj‚ÄºÔ∏è\\n\\nDziƒôki @anonymized_account \\n\\nhttps://t.co/w4nJSmo1J4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@anonymized_account Tak z ciekawo≈õci chcia≈Çam zpytaƒá czy uda≈Ço mu sie odkrƒôciƒá to pomy≈Çkowe g≈Çosowanie?  Czy ktos, co≈õ s≈Çyszal?\\n</td>\n",
       "      <td>@anonymized_account Z ciekawo≈õci chcia≈Çem zapytaƒá, czy uda≈Ço mu siƒô odkrƒôciƒá to b≈Çƒôdne g≈Çosowanie? Kto≈õ co≈õ s≈Çysza≈Ç?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@anonymized_account Wynik wynikiem, niech tu siƒô bez kontuzji sko≈Ñczy.\\n</td>\n",
       "      <td>@anonymized_account Wynik jest wynikiem, niech zako≈Ñczy siƒô tutaj bez obra≈ºe≈Ñ.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                    original  \\\n",
       "0                                                                            Justas Lasickas z golem dla Litwy U-21, kt√≥ra remisuje z Wyspami Owczymi 2:2.\\n   \n",
       "1                                                                                 @anonymized_account @anonymized_account Kostevycha rƒôka by≈Ça rozmy≈õlna ?\\n   \n",
       "2          @anonymized_account Ja ju≈º nie odczuwam, regularno≈õƒá codziennie do pracy, ≈õmiejƒô siƒô wiatru w twarz, czym mocniej wieje tym g≈Ço≈õniej si√© ≈õmiejƒô\\n   \n",
       "3                                                                       @anonymized_account @anonymized_account Nikt ciebie tu nie chce rasistowski pƒôtaku\\n   \n",
       "4                                                                                    #dividetourwarsaw zr√≥b ktos live spod stadionu prosze potrzebuje tego\\n   \n",
       "5                      @anonymized_account @anonymized_account @anonymized_account @anonymized_account @anonymized_account Kaliciaka mogli te≈º zaprosiƒá :)\\n   \n",
       "6                    @anonymized_account Mo≈ºe nie by≈Ço ciekawszych? :) a mo≈ºe ta agencja ma te≈º znajomo≈õci w gazecie i poprosili ≈ºeby o nim wspomnieƒá ? :)\\n   \n",
       "7   @anonymized_account @anonymized_account @anonymized_account Masz racjƒô w ka≈ºdym punkcie. I PiS te≈º ma i dok≈Çadnie wie co robi i z kim ma do czynienia.\\n   \n",
       "8                                                            W sumie to polubi≈Çam ju≈º zajƒôcia z konstrukcji przekazu reklamowego i prowadzƒÖcy jest ≈õwietny\\n   \n",
       "9                                                            T≈Çit aktualny szczeg√≥lnie dzisiaj‚ÄºÔ∏è\\n\\nDziƒôki @anonymized_account \\n\\nhttps://t.co/w4nJSmo1J4\\n   \n",
       "10                         @anonymized_account Tak z ciekawo≈õci chcia≈Çam zpytaƒá czy uda≈Ço mu sie odkrƒôciƒá to pomy≈Çkowe g≈Çosowanie?  Czy ktos, co≈õ s≈Çyszal?\\n   \n",
       "11                                                                                  @anonymized_account Wynik wynikiem, niech tu siƒô bez kontuzji sko≈Ñczy.\\n   \n",
       "\n",
       "                                                                                                                                                 rephrased  \n",
       "0                                                                          Justas Lasickas po golu dla Litwy U-21, kt√≥ry zremisowa≈Ç z Wyspami Owczymi 2-2.  \n",
       "1                                                                                     @anonymized_account @anonymized_account Rƒôka Kostevycha by≈Ça celowa?  \n",
       "2          @anonymized_account Ju≈º tego nie czujƒô, regularno≈õƒá codziennie do pracy, ≈õmiejƒô siƒô w twarz wiatrowi, im mocniej wieje, tym g≈Ço≈õniej siƒô ≈õmiejƒô  \n",
       "3                                                                          @anonymized_account @anonymized_account Nikt ciƒô tu nie chce rasistowski draniu  \n",
       "4                                                                                  #dividetourwarsaw czy kto≈õ na ≈ºywo spod stadionu proszƒô potrzebujƒô tego  \n",
       "5                        @anonymized_account @anonymized_account @anonymized_account @anonymized_account @anonymized_account Kaliciak te≈º m√≥g≈Ç zaprosiƒá :)  \n",
       "6                      @anonymized_account Mo≈ºe nie by≈Ço ciekawiej? :) a mo≈ºe ta agencja te≈º ma znajomo≈õci w gazecie i poprosili mnie o wzmiankƒô o nim? :)  \n",
       "7   @anonymized_account @anonymized_account @anonymized_account Masz racjƒô w ka≈ºdym punkcie. A PiS te≈º ma i dok≈Çadnie wie, co robi iz kim ma do czynienia.  \n",
       "8                                                                W sumie ju≈º mi siƒô podoba≈Çy zajƒôcia z budowy przekazu reklamowego i prowadzƒÖcy jest super  \n",
       "9                                                            Ttit aktualne szczeg√≥lnie dzisiaj‚ÄºÔ∏è\\n\\nDziƒôki @anonymized_account \\n\\nhttps://t.co/w4nJSmo1J4  \n",
       "10                                    @anonymized_account Z ciekawo≈õci chcia≈Çem zapytaƒá, czy uda≈Ço mu siƒô odkrƒôciƒá to b≈Çƒôdne g≈Çosowanie? Kto≈õ co≈õ s≈Çysza≈Ç?  \n",
       "11                                                                          @anonymized_account Wynik jest wynikiem, niech zako≈Ñczy siƒô tutaj bez obra≈ºe≈Ñ.  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 200\n",
    "rephrasing_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this approach is at least worth trying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def augment_data(\n",
    "    dataframe: pd.DataFrame,\n",
    "    new_ones: int,  # how many new observations from class \"1\" we want to get\n",
    "    new_twos: int,  # how many new observations from class \"2\" we want to get\n",
    ") -> pd.DataFrame:\n",
    "    ones_number = dataframe[dataframe[\"label\"] == 1].shape[0]\n",
    "    twos_number = dataframe[dataframe[\"label\"] == 2].shape[0]\n",
    "    assert new_ones <= ones_number\n",
    "    assert new_twos <= twos_number\n",
    "    \n",
    "    ones_indices = random.sample(range(ones_number), new_ones)\n",
    "    twos_indices = random.sample(range(twos_number), new_twos)\n",
    "    \n",
    "    original_ones = dataframe[dataframe[\"label\"] == 1][\"text\"].values[ones_indices]\n",
    "    original_twos = dataframe[dataframe[\"label\"] == 2][\"text\"].values[twos_indices]\n",
    "    \n",
    "    rephrased_ones = [rephrase_text(text) for text in tqdm(original_ones)]\n",
    "    rephrased_twos = [rephrase_text(text) for text in tqdm(original_twos)]\n",
    "    \n",
    "    rephrased_ones_df = pd.DataFrame({\n",
    "        \"text\": rephrased_ones,\n",
    "        \"label\": [1 for i in range(len(rephrased_ones))]\n",
    "    })\n",
    "    rephrased_twos_df = pd.DataFrame({\n",
    "        \"text\": rephrased_twos,\n",
    "        \"label\": [2 for i in range(len(rephrased_twos))]\n",
    "    })\n",
    "    \n",
    "    return pd.concat([dataframe, rephrased_ones_df, rephrased_twos_df], axis=\"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6892\n",
       "2     448\n",
       "1     190\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create 90 new observations from class \"1\" and 215 new observations from \"2\" class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [00:43<00:00,  2.05it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [01:47<00:00,  2.01it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train_augmented = augment_data(dataframe=df_train, new_ones=90, new_twos=215)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6892\n",
       "2     663\n",
       "1     280\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_augmented[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.879643\n",
       "2    0.084620\n",
       "1    0.035737\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_augmented[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.915272\n",
       "2    0.059495\n",
       "1    0.025232\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that percentage of both undersampled classes got bigger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A function for logging experiments into MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional\n",
    "\n",
    "def log_experiment(\n",
    "    experiment_name: str,\n",
    "    metrics: Dict[str, Any],\n",
    "    model: Optional[SVC] = None,\n",
    "    vectorizer: Optional[TfidfVectorizer] = None,\n",
    "    hyperparams: Optional[Dict[str, Any]] = None,\n",
    "    run_name: Optional[str] = None,\n",
    "    tag: str = Optional[None],\n",
    "):\n",
    "    \n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        \n",
    "        if hyperparams != None:\n",
    "            for param in hyperparams:\n",
    "                mlflow.log_param(param, hyperparams[param])\n",
    "            \n",
    "        for metric in metrics:\n",
    "            mlflow.log_metric(metric, metrics[metric])\n",
    "        \n",
    "        if model != None:\n",
    "            mlflow.sklearn.log_model(model, \"model\")\n",
    "        if vectorizer != None:\n",
    "            mlflow.sklearn.log_model(vectorizer, \"vectorizer\")\n",
    "        if tag != None:\n",
    "            mlflow.set_tag(\"tag1\", tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SVM and TFIDF with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf_default = TfidfVectorizer(max_features=df_train_augmented.shape[0])\n",
    "#just to make sure we don't have more features than observations\n",
    "svm_default = SVC(verbose=1)\n",
    "\n",
    "preprocessor = TextPreprocessor()\n",
    "evaluator = TextClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# text preprocessing\n",
    "df_train_augmented[\"text\"] = df_train_augmented[\"text\"].apply(lambda x: preprocessor.preprocess(x))\n",
    "df_val[\"text\"] = df_val[\"text\"].apply(lambda x: preprocessor.preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_default.fit_transform(df_train_augmented[\"text\"].values)\n",
    "X_val_tfidf = tfidf_default.transform(df_val[\"text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = df_train_augmented[\"label\"].values\n",
    "y_val = df_val[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]...*..*\n",
      "optimization finished, #iter = 5694\n",
      "obj = -413.500946, rho = -0.941106\n",
      "nSV = 4220, nBSV = 286\n",
      ".....*...*\n",
      "optimization finished, #iter = 8067\n",
      "obj = -872.366028, rho = -0.839806\n",
      "nSV = 5371, nBSV = 648\n",
      ".*\n",
      "optimization finished, #iter = 1396\n",
      "obj = -338.880396, rho = 0.751311\n",
      "nSV = 877, nBSV = 269\n",
      "Total nSV = 6461\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_default.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: SVC,\n",
    "    labels_train: np.ndarray,\n",
    "    labels_val: np.ndarray,\n",
    "    features_train: np.ndarray,\n",
    "    features_val: np.ndarray,\n",
    "    eval_object: TextClassificationEvaluator = evaluator,\n",
    "):\n",
    "    predictions_train = model.predict(features_train)\n",
    "    predictions_val = model.predict(features_val)\n",
    "    \n",
    "    train_metrics = evaluator.calculate_metrics(labels_train, predictions_train)\n",
    "    validation_metrics = evaluator.calculate_metrics(labels_val, predictions_val)\n",
    "    \n",
    "    return train_metrics, validation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_train, metrics_val = evaluate_model(\n",
    "    model=svm_default,\n",
    "    labels_train=y_train,\n",
    "    labels_val=y_val,\n",
    "    features_train=X_train_tfidf,\n",
    "    features_val=X_val_tfidf,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics:\n",
      "{'accuracy': 0.9624760689215061, 'f1_macro': 0.8420009498522497, 'f1_micro': 0.9624760689215061}\n",
      "\n",
      "--------------------\n",
      "\n",
      "Validation metrics:\n",
      "{'accuracy': 0.9215452011150936, 'f1_macro': 0.4065510938891632, 'f1_micro': 0.9215452011150936}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train metrics:\\n{metrics_train}\")\n",
    "print()\n",
    "print(\"-\"*20)\n",
    "print()\n",
    "print(f\"Validation metrics:\\n{metrics_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could expect, the model run on default hyperparameters is strongly overfitted.\n",
    "\n",
    "In the hyperparameter tuning process, I will use f1_marco on validation dataset as the optimization target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_to_log = {}\n",
    "\n",
    "for metric, value in metrics_train.items():\n",
    "    new_key = metric + \"_train\"\n",
    "    metrics_to_log[new_key] = value\n",
    "    \n",
    "for metric, value in metrics_val.items():\n",
    "    new_key = metric + \"_val\"\n",
    "    metrics_to_log[new_key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/03 13:03:47 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    }
   ],
   "source": [
    "log_experiment(\n",
    "    experiment_name=\"Default_hyperparameters\",\n",
    "    metrics=metrics_to_log,\n",
    "    model=svm_default,\n",
    "    vectorizer=tfidf_default,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning hyperparameters with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loading hyperparameters ranges\n",
    "svm_hyperparams, tfidf_hyperparams = ConfigParser.load_hyperparams(\"hyperparameters.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(\n",
    "    trial, \n",
    "    X_train, \n",
    "    X_test, \n",
    "    y_train, \n",
    "    y_test,\n",
    "    svm_hyperparams,\n",
    "    tfidf_hyperparams,\n",
    "    evaluator,\n",
    "):\n",
    "    svm_C = trial.suggest_loguniform('svm_c', *svm_hyperparams.C)\n",
    "    svm_kernel = trial.suggest_categorical('svm_kernel', svm_hyperparams.kernel)\n",
    "    svm_class_weight = svm_hyperparams.class_weight\n",
    "    tfidf_max_features = trial.suggest_int('tfidf_max_features', *tfidf_hyperparams.max_features)\n",
    "    tfidf_min_df = trial.suggest_int('tfidf_min_df', *tfidf_hyperparams.min_df)\n",
    "    tfidf_max_df = trial.suggest_uniform('tfidf_max_df', *tfidf_hyperparams.max_df)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_df=tfidf_max_df,\n",
    "        max_features=tfidf_max_features,\n",
    "        min_df=tfidf_min_df\n",
    "    )\n",
    "    \n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    \n",
    "    svm = SVC(\n",
    "        C=svm_C,\n",
    "        kernel=svm_kernel,\n",
    "        class_weight=svm_class_weight\n",
    "    )\n",
    "    \n",
    "    svm.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    y_pred = svm.predict(X_test_tfidf)\n",
    "    \n",
    "    f1_macro = evaluator.calculate_f1_macro(y_test, y_pred)\n",
    "    \n",
    "    return f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = df_train_augmented[\"text\"].values\n",
    "X_val = df_val[\"text\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_callback(study, trial):\n",
    "    best_trial = study.best_trial\n",
    "    if trial.number % 10 == 0 or trial.number == 199:\n",
    "        print(f\"Trial {trial.number}: {trial.value} Best trial so far: {best_trial.number}: {best_trial.value}\")\n",
    "\n",
    "        log_experiment(\n",
    "            experiment_name=\"hyperparams_tuning\",\n",
    "            metrics={\"f1_macro\": best_trial.value},\n",
    "            hyperparams=best_trial.params,\n",
    "            run_name=f\"trial_{trial.number}\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: 0.03757985719654265 Best trial so far: 0: 0.03757985719654265\n",
      "Trial 10: 0.4217346846256567 Best trial so far: 2: 0.4301355440304142\n",
      "Trial 20: 0.42054829993645715 Best trial so far: 17: 0.4589135397543051\n",
      "Trial 30: 0.40993178954134396 Best trial so far: 26: 0.46558393062556785\n",
      "Trial 40: 0.40802719172193536 Best trial so far: 31: 0.466316976213899\n",
      "Trial 50: 0.470975173187786 Best trial so far: 50: 0.470975173187786\n",
      "Trial 60: 0.47335940495360784 Best trial so far: 58: 0.481140752772768\n",
      "Trial 70: 0.4803065134099617 Best trial so far: 58: 0.481140752772768\n",
      "Trial 80: 0.47491313237317384 Best trial so far: 58: 0.481140752772768\n",
      "Trial 90: 0.40441337988636894 Best trial so far: 88: 0.48179449757396525\n",
      "Trial 100: 0.481140752772768 Best trial so far: 88: 0.48179449757396525\n",
      "Trial 110: 0.4009299026351485 Best trial so far: 88: 0.48179449757396525\n",
      "Trial 120: 0.4447613946678073 Best trial so far: 88: 0.48179449757396525\n",
      "Trial 130: 0.4800495375180718 Best trial so far: 88: 0.48179449757396525\n",
      "Trial 140: 0.47990862298273745 Best trial so far: 88: 0.48179449757396525\n",
      "Trial 150: 0.4776881875386929 Best trial so far: 88: 0.48179449757396525\n",
      "Trial 160: 0.4767211103442988 Best trial so far: 88: 0.48179449757396525\n",
      "Trial 170: 0.47393337566763644 Best trial so far: 88: 0.48179449757396525\n",
      "Trial 180: 0.4557691300369702 Best trial so far: 88: 0.48179449757396525\n",
      "Trial 190: 0.48049272382859587 Best trial so far: 88: 0.48179449757396525\n",
      "Trial 199: 0.47990862298273745 Best trial so far: 88: 0.48179449757396525\n"
     ]
    }
   ],
   "source": [
    "study.optimize(\n",
    "    lambda trial: objective(\n",
    "        trial,\n",
    "        X_train,\n",
    "        X_val,\n",
    "        y_train,\n",
    "        y_val,\n",
    "        svm_hyperparams,\n",
    "        tfidf_hyperparams,\n",
    "        evaluator,\n",
    "    ),\n",
    "    n_trials=200,\n",
    "    callbacks=[log_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm_c': 7.6495944342965165, 'svm_kernel': 'rbf', 'tfidf_max_features': 4692, 'tfidf_min_df': 1, 'tfidf_max_df': 0.518276935298537}\n"
     ]
    }
   ],
   "source": [
    "best_trial = study.best_trial\n",
    "\n",
    "best_params = best_trial.params\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_svm_hyperparams = {}\n",
    "best_tfidf_hyperparams = {}\n",
    "\n",
    "for key in best_params.keys():\n",
    "    if key.startswith(\"svm_\"):\n",
    "        best_svm_hyperparams[key.replace(\"svm_\", \"\")] = best_params[key]\n",
    "    elif key.startswith(\"tfidf_\"):\n",
    "        best_tfidf_hyperparams[key.replace(\"tfidf_\", \"\")] = best_params[key]\n",
    "\n",
    "best_svm_hyperparams[\"C\"] = best_svm_hyperparams[\"c\"]\n",
    "del best_svm_hyperparams[\"c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=7.6495944342965165, class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=7.6495944342965165, class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=7.6495944342965165, class_weight='balanced')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tfidf = TfidfVectorizer(**best_tfidf_hyperparams)\n",
    "best_svm = SVC(**best_svm_hyperparams, class_weight=\"balanced\")\n",
    "\n",
    "X_train_tfidf = best_tfidf.fit_transform(X_train)\n",
    "X_val_tfidf = best_tfidf.transform(X_val)\n",
    "\n",
    "best_svm.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_metrics_train, best_metrics_val = evaluate_model(\n",
    "    model=best_svm,\n",
    "    labels_train=y_train,\n",
    "    labels_val=y_val,\n",
    "    features_train=X_train_tfidf,\n",
    "    features_val=X_val_tfidf,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics:\n",
      "{'accuracy': 0.9941289087428207, 'f1_macro': 0.9790723331833172, 'f1_micro': 0.9941289087428207}\n",
      "\n",
      "--------------------\n",
      "\n",
      "Validation metrics:\n",
      "{'accuracy': 0.9203504579848666, 'f1_macro': 0.48179449757396525, 'f1_micro': 0.9203504579848666}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train metrics:\\n{best_metrics_train}\")\n",
    "print()\n",
    "print(\"-\"*20)\n",
    "print()\n",
    "print(f\"Validation metrics:\\n{best_metrics_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuning process improved results a little, but there is still strong overfitting. However, building the best possible solution is not the main purpose, so let's keep that results.\n",
    "\n",
    "By the way, the fact that accuracy is always equal to f1_micro is very interesting. The number of true positives, true negatives, false positives, and false negatives must be the same across all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_metrics_to_log = {}\n",
    "\n",
    "for metric, value in best_metrics_train.items():\n",
    "    new_key = metric + \"_train\"\n",
    "    best_metrics_to_log[new_key] = value\n",
    "    \n",
    "for metric, value in best_metrics_val.items():\n",
    "    new_key = metric + \"_val\"\n",
    "    best_metrics_to_log[new_key] = value\n",
    "\n",
    "log_experiment(\n",
    "    experiment_name=\"Best_hyperparams\",\n",
    "    metrics=best_metrics_to_log,\n",
    "    model=best_svm,\n",
    "    vectorizer=best_tfidf,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I downloaded best SVM and TFIDF objects and saved them in the /models directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"models/model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open(\"models/vectorizer.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "assert isinstance(model, SVC)\n",
    "assert isinstance(vectorizer, TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running best objects on test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the evaluation process on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data/test/test_set_only_text.txt\", \"r\") as f:\n",
    "    test_examples = f.readlines()\n",
    "\n",
    "with open(\"data/test/test_set_only_tags.txt\", \"r\") as f:\n",
    "    test_labels = f.readlines()\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    \"text\": test_examples,\n",
    "    \"label\": test_labels,\n",
    "})\n",
    "\n",
    "df_test[\"label\"] = df_test[\"label\"].apply(lambda x: x.replace(\"\\n\", \"\"))\n",
    "df_test[\"label\"] = df_test[\"label\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@anonymized_account Spoko, jak im Duda z Morawieckim zam√≥wiƒÖ po piƒôƒá piw to wszystko bƒôdzie ok.\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@anonymized_account @anonymized_account Ale on tu nie mia≈Ç szans jej zagrania, a ta 'proba' to czysta prowizorka.\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@anonymized_account No czy Prezes nie mia≈Ç racji, m√≥wiƒÖc,ze to sƒÖ zdradzieckie mordy? No czy nie mia≈Ç racji?üòÅüòÅ\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@anonymized_account @anonymized_account Przecie≈º to nawet nie jest przewrotka üòÇ\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@anonymized_account @anonymized_account Owszem podatki tak. Ale nie w takich okoliczno≈õciach. Czemu Ma≈Çysza odpalili z teamu Orlen?\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    text  \\\n",
       "0                                      @anonymized_account Spoko, jak im Duda z Morawieckim zam√≥wiƒÖ po piƒôƒá piw to wszystko bƒôdzie ok.\\n   \n",
       "1                    @anonymized_account @anonymized_account Ale on tu nie mia≈Ç szans jej zagrania, a ta 'proba' to czysta prowizorka.\\n   \n",
       "2                       @anonymized_account No czy Prezes nie mia≈Ç racji, m√≥wiƒÖc,ze to sƒÖ zdradzieckie mordy? No czy nie mia≈Ç racji?üòÅüòÅ\\n   \n",
       "3                                                      @anonymized_account @anonymized_account Przecie≈º to nawet nie jest przewrotka üòÇ\\n   \n",
       "4  @anonymized_account @anonymized_account Owszem podatki tak. Ale nie w takich okoliczno≈õciach. Czemu Ma≈Çysza odpalili z teamu Orlen?\\n   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test[\"text\"] = df_test[\"text\"].apply(lambda x: preprocessor.preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spoko duda morawieckim zam√≥wiƒÖ piƒôƒá piw ok</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mia≈Ç szans zagrania proba czysta prowizorka</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prezes mia≈Ç racji m√≥wiƒÖcze zdradzieckie mordy mia≈Ç racji</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>przewrotka</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>podatki tak takich okoliczno≈õciach ma≈Çysza odpalili teamu orlen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              text  label\n",
       "0                       spoko duda morawieckim zam√≥wiƒÖ piƒôƒá piw ok      0\n",
       "1                      mia≈Ç szans zagrania proba czysta prowizorka      0\n",
       "2         prezes mia≈Ç racji m√≥wiƒÖcze zdradzieckie mordy mia≈Ç racji      0\n",
       "3                                                       przewrotka      0\n",
       "4  podatki tak takich okoliczno≈õciach ma≈Çysza odpalili teamu orlen      0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_tfidf = vectorizer.transform(df_test[\"text\"].values)\n",
    "y_test = df_test[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_preds = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics values on test set:\n",
      "{'accuracy': 0.871, 'f1_macro': 0.4379092184593614, 'f1_micro': 0.871}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Metrics values on test set:\\n{evaluator.calculate_metrics(y_test, y_test_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance got even worse on previously unseen data. If we want to achieve better results, we would have to apply several overfitting prevention techniques. Getting more data would be a good idea, as we had only around 10 000 observations in the training dataset. Also it may be a good idea to do some research about different text augmentation techniques, and use an algorithm which is less overfitting-prone.\n",
    "\n",
    "However, let's consider the current model and vectorizer as prototype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
