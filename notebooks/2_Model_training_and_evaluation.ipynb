{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Model training and evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the process of training a classification model for a hate-speech dataset. The possible targets for each entity are:\n",
    "- 0: non-harmful\n",
    "- 1: cyberbullying (addressed towards a single person)\n",
    "- 2: hate-speech (addressed towards a public person/entity/large group)\n",
    "\n",
    "The original training set will be split into two subsets: 75% for training the models, 25% for validation.\n",
    "\n",
    "After the splitting operation, I will perform data augmentation on the training subset for the undersampled classes 1 and 2.\n",
    "\n",
    "The augmentation logic will be using the Google Translate API to translate some sentences from Polish to English, and then back to Polish.\n",
    "\n",
    "This way, we should get the sentences having the same context, but put in a different words.\n",
    "However if this causes data duplication, I will not proceed with this technique.\n",
    "\n",
    "Every observation will be cleaned using the TextPreprocessor class defined in the codebase. The steps are:\n",
    "- putting all text to lowercase,\n",
    "- removing emojis,\n",
    "- removing user mentions (ex. @mariusz)\n",
    "- removing stop words,\n",
    "- removing URL addresses,\n",
    "- removing special characters like new line, carriage return, tab,\n",
    "- removing punctuation marks,\n",
    "- removing redundant spaces.\n",
    "\n",
    "I decided to use the SVM algorithm, which should be a good balance between simplicity and performance. Also, it was SVM which took the first place in the PolEval compoetition :)\n",
    "\n",
    "The text data will have to be transformed into numbers. I will use the TF-IDF vectorizer for that purpose.\n",
    "\n",
    "In the first approach, both SVM and TFIDF will be trained on default hyperparameters.\n",
    "\n",
    "In the second approach, I will perform a randomized search hyperparameter tuning, using the hyperparameters ranges specified in the \"hyperparameters.yaml\" file. I will choose the best configuration at the end.\n",
    "\n",
    "The results of both approaches will be evaluated by the TextClassificationEvaluator class defined in the codebase.\n",
    "\n",
    "Both approaches will be logged in MLflow.\n",
    "\n",
    "The approaches will be tested on the original \"test\" dataset.\n",
    "When choosing the better approach, I will take the following things into consideration:\n",
    "- performance on training set,\n",
    "- performance on validation and test sets,\n",
    "- difference in performance between train and validation/test.\n",
    "\n",
    "The approach with best results will be chosen to be deployed as a working service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de39fcc35ac449c3e591e9bd87a331e24ccc631c3d6f9d81aba0de5aff5ba87a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
